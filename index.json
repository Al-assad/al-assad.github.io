[{"content":"A software engineer who occasionally ponders some odd questions, functional programming fanatic with a focus on Scala3, Cloud Native and Big Data Domain.\nMy personal open-source project repository: 😆LinsOSS\nRecent Let‘s Expand Citus Co-location Single-Shard Distributed Tables 26 October 2023\u0026middot;5 mins citus postgres Explores how to enhance Citus for managing single-shard distributed tables that should be co-located efficiently, particularly in multi-tenant environments. Hacker News Digest - 2023.06.22 22 June 2023\u0026middot;2 mins hacker news 探索云原生领域的多样性景观, Quirky, Hashing, DevPod: 无服务商锁定的代码即开发环境平台, Exit traps 让你的 Bash 脚本更加健壮, pg_easy_replicate 实现零停机的 Postgres 版本迁移 Hacker News Digest - 2023.06.19 19 June 2023\u0026middot;1 min hacker news Novel：Notion 风格的文本编辑器, Bloop：基于 GPT-4 代码库阅读工具, Dolt: Git 版本化数据, Resend: 现代化邮件发送 API 平台, 通过 Stable Diffusion 制作艺术化的二维码 在 Postgres 上复刻 AskBend！ 16 April 2023\u0026middot;2 mins postgres gpt 起因是在 3 月的时候刷到 Databend ai_to_sql 的一条 PR, feat: add ai_to_sql transalte natual lanauge to SQL based on your table schema by BohuTANG \u0026hellip; ","date":"26 October 2023","permalink":"/","section":"","summary":"A software engineer who occasionally ponders some odd questions, functional programming fanatic with a focus on Scala3, Cloud Native and Big Data Domain.\nMy personal open-source project repository: 😆LinsOSS\nRecent Let‘s Expand Citus Co-location Single-Shard Distributed Tables 26 October 2023\u0026middot;5 mins citus postgres Explores how to enhance Citus for managing single-shard distributed tables that should be co-located efficiently, particularly in multi-tenant environments.","title":""},{"content":"","date":"26 October 2023","permalink":"/tags/citus/","section":"Tags","summary":"","title":"citus"},{"content":"In a multi-tenant scenario, Citus adeptly handles tenant partitioning for tables with the same structure while maintaining a robust co-location strategy.\nHowever, when dealing with tables possessed by different tenants with completely distinct structures, especially when these tables have relatively small data volumes (e.g., an average total row count not exceeding 5000), the direct use of Citus\u0026rsquo;s distributed tables may not yield the desired results. The query performance may suffer due to the presence of multiple partitions, especially when these partitions are distributed across different nodes. In such cases, it is often more effective to store the table on a standard PostgresSQL node.\nIn this use case, our objective is to achieve tenant data co-location on multiple nodes for single-shard tables, with each table maintaining only one replica, much like a standalone PostgresSQL instance. We aim to ensure that co-located data (belonging to the same tenant) resides on the same physical node, all while leveraging Citus\u0026rsquo;s inherent sharding and rebalancing capabilities.\nHow to Implement ? # One approach to achieving this is by encapsulating native PostgreSQL tables into a single-shard Citus distributed table and using Citus\u0026rsquo;s sharding strategy to schedule it onto the correct nodes. This enables the goal of having a small, single-node storage table co-located with corresponding Citus distributed tables for other tenants.\nWe can achieve this behavior in a lightweight manner through the use of a Postgres User-Defined Function (UDF) Extension.\nPostgres Extension Code # -- Citus single shard table udf -- init global tid_mark table create or replace procedure citus.init_tid_mark() language plpgsql as $$ declare tid_mark_count int; begin -- create global tid_mark table create table if not exists citus.tid_mark ( tid text primary key ); -- create distributed table for tid_mark select count(*) from citus_tables where table_name = \u0026#39;citus.tid_mark\u0026#39;::regclass into tid_mark_count; if (tid_mark_count = 0) then perform create_distributed_table(\u0026#39;citus.tid_mark\u0026#39;, \u0026#39;tid\u0026#39;); end if; end; $$; -- whether the table contains only one single shard create or replace function citus.is_single_shard_table(tbl_name text) returns boolean language plpgsql as $$ declare r boolean; begin select count(shardid) = 1 from citus_shards where table_name = tbl_name::regclass into r; return r; end; $$; -- whether the single shard table need to be rebalanced create or replace function citus.is_single_shard_table_colocated(tbl_name text, tid text) returns boolean language plpgsql as $$ declare ori_nodename text; ori_nodeport integer; target_nodename text; target_nodeport integer; begin if citus.is_single_shard_table(tbl_name) = false then return true; else select nodename, nodeport from citus_shards where table_name = tbl_name::regclass into ori_nodename, ori_nodeport; select nodename, nodeport from citus_shards where shardid = (select shardid from pg_dist_shard where logicalrelid = \u0026#39;citus.tid_mark\u0026#39;::regclass and (select hashtext(tid)) between shardminvalue::integer and shardmaxvalue::integer limit 1) into target_nodename, target_nodeport; return not (ori_nodename = target_nodename and ori_nodeport = target_nodeport); end if; end; $$; -- co-locate the single shard table in citus cluster create or replace function citus.colocate_single_shard_table(tbl_name text, tid text) returns record language plpgsql as $$ declare shard_id bigint; ori_nodename text; ori_nodeport integer; target_nodename text; target_nodeport integer; r record; begin if citus.is_single_shard_table(tbl_name) = false then return r; else select shardid, nodename, nodeport from citus_shards where table_name = tbl_name::regclass into shard_id, ori_nodename, ori_nodeport; select nodename, nodeport from citus_shards where shardid = (select shardid from pg_dist_shard where logicalrelid = \u0026#39;citus.tid_mark\u0026#39;::regclass and (select hashtext(tid)) between shardminvalue::integer and shardmaxvalue::integer limit 1) into target_nodename, target_nodeport; select shard_id, target_nodename, target_nodeport into r; if (ori_nodename = target_nodename and ori_nodeport = target_nodeport) then return r; else perform citus_move_shard_placement(shard_id, ori_nodename, ori_nodeport, target_nodename, target_nodeport); return r; end if; end if; end; $$; -- randomly place the single shard table create or replace function citus.randomly_single_shard_table(tbl_name text) returns record language plpgsql as $$ declare shard_id bigint; ori_nodename text; ori_nodeport integer; target_nodename text; target_nodeport integer; r record; begin if citus.is_single_shard_table(tbl_name) = false then return r; else select shardid, nodename, nodeport from citus_shards where table_name = tbl_name::regclass into shard_id, ori_nodename, ori_nodeport; select node_name, node_port from citus_get_active_worker_nodes() order by random() limit 1 into target_nodename, target_nodeport; select shard_id, target_nodename, target_nodeport into r; if (ori_nodename = target_nodename and ori_nodeport = target_nodeport) then return r; else perform citus_move_shard_placement(shard_id, ori_nodename, ori_nodeport, target_nodename, target_nodeport); return r; end if; end if; end; $$; -- create a distributed table with only one shard create or replace function citus.create_single_shard_distributed_table(tbl_name text) returns void language plpgsql as $$ declare ns_space text; rel_name text; has_pri_col boolean; shard_col text; begin select nspname, relname from pg_catalog.pg_class as c join pg_catalog.pg_namespace as ns on c.relnamespace = ns.oid where c.oid = tbl_name::regclass::oid into ns_space, rel_name; select count(column_name) \u0026gt; 0 from information_schema.key_column_usage where table_catalog = current_database() and table_schema = ns_space and table_name = rel_name into has_pri_col; if (has_pri_col) then -- using the first primary key column as shard key select column_name from information_schema.key_column_usage where table_catalog = current_database() and table_schema = ns_space and table_name = rel_name order by ordinal_position limit 1 into shard_col; perform create_distributed_table(tbl_name, shard_col, shard_count := 1); else -- using the first column as shard key select column_name from information_schema.columns where table_catalog = current_database() and table_schema = ns_space and table_name = rel_name order by ordinal_position limit 1 into shard_col; perform create_distributed_table(tbl_name, shard_col, shard_count := 1); end if; end ; $$; Usage # Initialize global distribution identifier after the citus cluster initialization is complete:\ncall citus.init_tid_mark() Create a distributed single shard table, there are two shard placement strategies:\nCo-located with tenant-id: citus.colocate_single_shard_table Random distribution: citus.randomly_single_shard_table -- create a local table on coordinator node create table test ( f1 text, f2 int, f3 int ); -- wrapper the local table \u0026#39;test\u0026#39; as distributed single shard table select citus.create_single_shard_distributed_table(\u0026#39;test\u0026#39;) -- strategy A: co-located with tenent-id select citus.colocate_single_shard_table(\u0026#39;test\u0026#39;, \u0026#39;f1741e9e-fbbb-41f3-9160-77109a073f75\u0026#39;) -- strategy B: random distributed select citus.randomly_single_shard_table(\u0026#39;test\u0026#39;) By default, the first primary key column of the wrapped table or this first normal column (in case it does not contain any primary key) is used as the shard column of the citus distributed table.\nWhen the citus cluster is scaling out, consider rebalancing distributed single shard table to the correct tenent_id co-located node:\nselect citus.colocate_single_shard_table(\u0026#39;test\u0026#39;) Of course, the distributed single shard table itself is a citus distributed table and can be converted to a citus native distributed table at any time.\n-- convert to citus native distributed table select alter_distributed_table(\u0026#39;test\u0026#39;, distribution_column := \u0026#39;f2\u0026#39;, shard_count := 32) ","date":"26 October 2023","permalink":"/posts/expand-citus-single-shard-table/","section":"Posts","summary":"Explores how to enhance Citus for managing single-shard distributed tables that should be co-located efficiently, particularly in multi-tenant environments.","title":"Let‘s Expand Citus Co-location Single-Shard Distributed Tables"},{"content":"","date":"26 October 2023","permalink":"/tags/postgres/","section":"Tags","summary":"","title":"postgres"},{"content":"","date":"26 October 2023","permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":"22 June 2023","permalink":"/tags/hacker-news/","section":"Tags","summary":"","title":"hacker news"},{"content":" Reading on Craft.do 2023.06.20 - 06.22\n探索云原生领域的多样性景观 # Explore the Variety of Cloud-Native Landscape: the Dynamic World of Kubernetes and Beyond, Seifeddine Rajhi.\nhttps://itnext.io/explore-the-variety-of-cloud-native-landscape-the-dynamic-world-of-kubernetes-and-beyond-dbf14d73d22c\n文章从以下 6 个方面系统地梳理了 CNCF 生态的主要类别景观：\n供应商（Provisioning）； 运行时（Runtime）； 编排管理（Orchestration \u0026amp; Management）； 应用开发（App Definition \u0026amp; Development）； 可观测性分析（Observability \u0026amp; Analysis）； 平台（Platforms） 很适合作为了解云原生生态概览的入门文章，另，这张 meme 我双手赞同 🙌🏻。\nQuirky: AI 制作炫酷二维码工具 # replicate/quirky An open-source tool for making really cool QR codes with AI JavaScript 196 20 在 Hacker News Digest - 2023.06.19 中介绍了文章《如何通过 Stable Diffusion 生成艺术二维码》，Quirky 带来了一个云上的版本，基于 Replicate 云机器学习平台和 Multi-ControlNet 分层控制模型，可以直接访问 quirky.replicate.dev 进行体验。\nHN Ref： https://news.ycombinator.com/item?id=36411246\nHashing：图解哈希函数原理 # https://samwho.dev/hashing/\n文章以图例、可视化交互的形式解释了 Hash 函数的工作原理，介绍了 Hash 函数的一个重要的评估标准雪崩效应（Avalanche Effect）。着重对比了 murmur3 和 stringSum 两种 Hash 算法，以可视化互动的方式演示了 murmur3 如何通过 randomisation 解决高相似输入引发的冲突。\nHN Ref： https://news.ycombinator.com/item?id=36401747\nDevPod：无服务商锁定的代码即开发环境平台 # loft-sh/devpod Codespaces but open-source, client-only and unopinionated: Works with any IDE and lets you use any cloud, kubernetes or just localhost docker. Go 4901 217 类似 Coder 的代码即开发环境平台（Dev-environment-as-code）， Codespaces 的开源替代品。可以在任意基础设施启动可复制的开发环境，兼容 Intellij、VSCode 等主流 IDE，支持本地 Docker、Kubernetes、GCP、AWS、Azure 等基础设施供应方。\nHN Ref： https://news.ycombinator.com/item?id=36407477\n\u0026ldquo;Exit traps\u0026rdquo; 让你的 Bash 脚本更加健壮 # How \u0026ldquo;Exit Traps\u0026rdquo; Can Make Your Bash Scripts Way More Robust And Reliable.\nhttp://redsymbol.net/articles/bash-exit-traps/\n文章介绍了在 Bash script 中使用 exit traps 来实现过脚本过早退出时的资源清理行为，从而提高脚本的健壮和稳定。\nHN Ref: https://news.ycombinator.com/item?id=36400465\npg_easy_replicate 实现零停机的 Postgres 版本迁移 # shayonj/pg_easy_replicate Easily setup logical replication and switchover to new database with minimal downtime Ruby 731 7 pg_easy_replicate 是一个开源的 Postgres 逻辑复制 CLI 工具，可以实现不同版本 PG 之间的数据逻辑复制，其中最主要的场景实现零数据丢失、最小停机时间的 PG 在线升级。\n类似项目有 pgEdge 于 2022 年开源的 PG 拓展 Spock：\npgEdge/spock pgEdge Multi-master Extension C 77 11 HN Ref： https://news.ycombinator.com/item?id=36405761\n","date":"22 June 2023","permalink":"/posts/hacker-news-digest-20230622/","section":"Posts","summary":"探索云原生领域的多样性景观, Quirky, Hashing, DevPod: 无服务商锁定的代码即开发环境平台, Exit traps 让你的 Bash 脚本更加健壮, pg_easy_replicate 实现零停机的 Postgres 版本迁移","title":"Hacker News Digest - 2023.06.22"},{"content":" Reading on Craft.do Novel：Notion 风格的文本编辑器 # steven-tey/novel Notion-style WYSIWYG editor with AI-powered autocompletion. TypeScript 8943 814 Novel 是一个开源的 Notion 风格的 WYSIWYG（所见即所得）文本编辑器，基于 Next.js、TailwindCSS 编写，并借助 OpenAI 提供了 AI 自动补全的特性。具有十分浓烈的 Vercel 味，毕竟是 Vercel 的 Senior DA Steven Tey 的作品。\nSteven Tey 最近有一期接受 kfund 采访的关于开发者关系的 Podcast 十分值得一听：\n#PodKast 181 Steven Tey (Vercel): understanding the role of developer relations\nHN Ref： https://news.ycombinator.com/item?id=36360789\nBloop：基于 GPT-4 代码库阅读工具 # BloopAI/bloop bloop is a fast code search engine written in Rust. TypeScript 7968 509 Bloop 是一个 Rust 编写的代码检索引擎，基于 GPT-4 以自然语言对话的方式来检索、回答有关代码库的问题，支持本地、远程 Github 代码仓库两种来源。这对于理解陌生项目十分有效，同时支持基于已有上下文编写新代码，由于对索引了整体代码，从结果的相关性上要略好于 Github Copilot。\nBloop 的查询索引由 Tantivy 和 Qdrant 提供，Tantivy 是一个 Rust 编写的类似 Apache Lucene 的全文搜索引擎，Qdrant 是 Rust 编写的矢量数据库，而客户端则是这几年广受欢迎的 Tauri，All in Rust 了属于是 🤣。\n属实良心的是，Bloop 的免费帐户目前没有硬性限制，只有在个人超过 20 个用户或 100 个同步仓库才会降低相应的性能。\nHN Ref： https://news.ycombinator.com/item?id=36260961\nDolt: Git 版本化数据 # dolthub/dolt Dolt – Git for Data Go 15686 447 Dolt 是一个以类 Git 进行版本控制的 SQL 数据库，即类似 Git 一样的 fork、clone、branch、merge、pull、push 的操作来更新数据，同时以 SQL 来查询数据，就像Git 和 MySQL 的缝合怪（It\u0026rsquo;s like Git and MySQL had a baby）。\n此外他们还创建 DoltHub 项目用于共享用户公开的 Dolt 数据，这为解决公共领域的数据集的变迁、溯源提供了一种新的思路。\nhttps://www.dolthub.com/\nHN Ref： https://news.ycombinator.com/item?id=36152590\n（原 HN 其实是讨论 DoltHub 上一个美国社区医院价格数据集的 XD）\nResend: 现代化邮件发送 API 平台 # resend.com\nResend 提供了一个现代化的邮件发送平台，专注于提供最佳的开发人员体验。核心卖点是可以基于 React 而非过时的布局来编写复杂的 HTML 邮件内容，同时提供邮件发送的事务性、可观察性和高速性能。\nHN Ref： https://news.ycombinator.com/item?id=36309120\n通过 Stable Diffusion 制作艺术化的二维码 # How to make a QR code with Stable Diffusion - Stable Diffusion Art\n文章介绍了如何通过 Stable Diffusion ControlNet 拓展生成艺术化的二维码。\nHN Ref: https://news.ycombinator.com/item?id=36285630\n🦑 Hacker News Digest Archive\n","date":"19 June 2023","permalink":"/posts/hacker-news-digest-20230619/","section":"Posts","summary":"Novel：Notion 风格的文本编辑器, Bloop：基于 GPT-4 代码库阅读工具, Dolt: Git 版本化数据, Resend: 现代化邮件发送 API 平台, 通过 Stable Diffusion 制作艺术化的二维码","title":"Hacker News Digest - 2023.06.19"},{"content":"","date":"16 April 2023","permalink":"/tags/gpt/","section":"Tags","summary":"","title":"gpt"},{"content":" Reading on Craft.do 起因是在 3 月的时候刷到 Databend ai_to_sql 的一条 PR：\nfeat: add ai_to_sql transalte natual lanauge to SQL based on your table schema by BohuTANG · Pull Request #10637 · datafuselabs/databend 于是就开始关注 databend 在 GPT-integration 的动向，然后在接下来的几个星期里，databend 以 built-in functoin 的形式陆续实现了一系列基于 OpenAI 的拓展功能。\nAI Functions | Databend\n正当我猜测 Databend 是不是要实现个 ChatDoc 的时候， Askbend 上线了，然后作为乐子人的我不出意料玩地很开心。 于是在读了一遍 Askbend 和 Databend AI function 代码的那个晚上，我突发奇想，何不乐上加乐，手搓一个 Postgres 的实现？\nAskBend 的实现 # AskBend 的实现文档搜索的过程分为两个主要部份：Doc Vector Embeddings \u0026amp; Query。\n将文档内容分割为合适长度的小节，计算每个小节的特征向量并存储。用户提问时，计算提问内容的特征向量，并查询余弦距离最近的几个文档小节，组合成 Promt 调用 OpenAI Completion API 获取结果。\n其中的关键步骤 Embedding 计算，向量余弦距离计算，自然语言补全依赖 Databend 新实现的几个 AI Function：\nai_embedding_vector ai_text_completion cosine_distance 实际上除了 osine_distance 之外，另外两个函数是对 OpenAI API 比较直白的调用封装，虽然 OpenAI 的 embedding 质量一般，但是胜在省事 🤣。\n让我们来进一步分析这两个过程的具体实现，让我看看.jpg。\n文档嵌入过程 # 端点代码位于 https://github.com/datafuselabs/askbend/blob/main/app/bin/ask.rs#L47，AksBend 实现为一个 CLI-Tool。\nStep-1: 文档解析 # askbend/markdown.rs at main · datafuselabs/askbend\n遍历目标文档目录下的所有 Markdown，将其按照 Heading 分割为内容小节，同时将长度小于 min_section_len (默认 1024) 的小节合并到上一个小节，避免过短的内容小节。\n这种分割方式十分地暴力，某个小节里很容易出现相关性较低的内容，比如某一个 H1 的小节因为长度过短折叠到了上一个相关性很低 H2 的小节里，更复杂的内容划分算法设计很麻烦，所以 “先实现了再说” 大概是虎哥当时脑海中的想法，这十分地合理（bushi。\nStep-2: 存储文档小节 # askbend/db.rs at 7babbdb197f573bdb462fedc2a31be206114e8bd · datafuselabs/askbend\n将 Step-1 的解析结果写入以下结构的表中：\nCREATE TABLE doc ( path VARCHAR, content VARCHAR, embedding ARRAY(FLOAT32) ); Step-3: 计算节选 Embedding # askbend/db.rs at main · datafuselabs/askbend\n调用 Databend ai_embedding_vector 计算所有小节限定最大内容长度的 vector embedding。\nUPDATE {{ database }}.{{ table }} SET embedding = ai_embedding_vector(left(concat(path, content),{{max_content_length}})) WHERE length(embedding)=0\u0026#34; ai_embedding_vector 实际上是对 OpenAI Embeddings API 的调用封装，使用了 text-embedding-ada-002 ，最大输入 token 是 8191， 输出尺寸为 1536。\nEmbedding 一种常用的离散特征的高纬向量投射方式，其中最大的问题在于不同生成算法和语料造成的玄学问题，尤其是恶梦一般的调参炼丹过程，自行实现要达到比较好的效果成本不低。\n所以原汤化原食，我出钱 OpenAI 出力，美事一桩，况且在这种一次性小规模场景上，也就不到一美元的开销。\n文档查询过程 # 断点代码位于： askbend/app/src/dal/db.rs#L169\nStep-1：计算 Input 文本的 Embedding # askbend/db.rs at main · datafuselabs/askbend\n同样地，实际是通过 ai_embedding_vector 调用 OpenAI Embeddings API，获取用户输入文本的 Embedding Vector。\nStep-2: 获取相似内容小节 # askbend/db.rs at main · datafuselabs/askbend\n获取 Step-1 的 Vector 结果余弦距离最近的 N 个内容小节：\nSELECT content, distance FROM ( SELECT content, cosine_distance({{ query_embedding }}, embedding) AS distance FROM {{ database }}.{{ table }} WHERE length(embedding) \u0026gt; 0 AND length(content) \u0026gt; {{ min_content_lenggth }} ORDER BY distance ASC LIMIT {{ top }} ) WHERE distance \u0026lt;= {{ min_distince }} Step-3: 从 OpenAI API 获取结果补全 # askbend/db.rs at main · datafuselabs/askbend\n文档小节和用户问题组装的 prompt 格式为：\nDocumentation sections: {{context}} Question: {{query}} 接着通过 Databend ai_text_completion 函数获取补全结果：\nSELECT ai_text_completio(\u0026#34;\u0026lt;prompt\u0026gt;\u0026#34;) ai_text_completion 实际上是对 Open AI Text Completion API 的封装调用，使用 text-davinci-003 模型。\n个人感觉更换为 Chat Completion API，使用 gpt-3.5-turbo 或 gpt-4 模型，设计好 prompt 不要让 gpt 胡言乱语可以有更好的返回结果。\n中场 # 以上就是整个 AskBend 的实现过程，虽然这是一个比较赶的项目产物，但是在很短是实现周期内，借助 OpenAI 十分巧妙地实现了一个 SQL-based knowledge，是个很棒的项目😃。\n加上 Databend 更早实现 ai_to_sql，整个思路可以在大部份支持向量计算的 Database 里实现出来，尤其是支持 UDF 的 Databse 里可以十分快速地整活，蹭 GPT 的热度可太乐了。\n在 Postgres 上复刻！ # 作为一个网路乐子人，我当然不能错过这么有意思的整活，于是我花了一个周末在 Postgres 上复刻 AskBend 🤣。\n项目 Github： https://github.com/Al-assad/postgres-gpt\nPostgres 具备了 2 个基本条件：\npgvector：拓展支持向量结构的存储，和简单的距离计算算法（余弦/内积距离）； pl/python：十分方便的 python udf 编写，openai 提供的 python sdk 直接抄； 实现形式是十分轻量的 Postgres Python UDF，用户开发修改可以直接在线修改相关函数的实现代码，相关的实现基本是像素级一比一抄 Askbend，只不过改进了文档查询为 Chat Completion 方式，设计了以下的 System Prompt：\nYou are an assistant with the following background knowledge: {{documentation}} 实际从用户意图的理解上看，要好于 Text Completion 方式，只不过还是有概率发生 Chat Completion 胡言乱语的传统艺能。\n","date":"16 April 2023","permalink":"/posts/replicate-askbend-on-postgres/","section":"Posts","summary":"起因是在 3 月的时候刷到 Databend ai_to_sql 的一条 PR, feat: add ai_to_sql transalte natual lanauge to SQL based on your table schema by BohuTANG \u0026hellip;","title":"在 Postgres 上复刻 AskBend！"},{"content":"","date":"13 June 2022","permalink":"/posts/","section":"Posts","summary":"","title":"Posts"},{"content":"","date":"1 January 0001","permalink":"/authors/","section":"Authors","summary":"","title":"Authors"},{"content":"","date":"1 January 0001","permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":"1 January 0001","permalink":"/series/","section":"Series","summary":"","title":"Series"}]